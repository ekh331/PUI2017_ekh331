{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Skeleton of Assignment 4:\n",
    "\n",
    "test if the distributions of \n",
    "    \n",
    "### 1) trip duration of bikers that ride during the day vs night\n",
    "### 2) age of bikers for trips originating in Manhattan and in Brooklyn\n",
    "    \n",
    "are different. Use 3 tests: KS, Pearson's, Spearman's. \n",
    "    \n",
    "Use the scipy.stats functions scipy.stats.ks_2samp, scipy.stats.pearsonr, scipy.stats.spearmanr. \n",
    "    \n",
    "For the KS do the test with the entire dataset and with a subset 200 times smaller\n",
    "    \n",
    "Choose a single significant threshold for the whole exercise. \n",
    "    \n",
    "For each test phrase the Null Hypothesis in words.\n",
    "    \n",
    "Describe the return of the scipy function you use in each case.\n",
    "    \n",
    "State the result in terms of rejection of the Null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:48:06.390950",
     "start_time": "2017-10-05T16:48:04.815178"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/rh/anaconda/root/envs/PUI2016_Python2/lib/python2.7/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/cusp/ekh331/PUIdata'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my usual imports and setups\n",
    "import random \n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "#imports downloader\n",
    "from getCitiBikeCSV import getCitiBikeCSV\n",
    "%pylab inline\n",
    "\n",
    "import os\n",
    "\n",
    "os.getenv(\"PUIDATA\")\n",
    "#this makes my plots pretty! but it is totally not mandatory to do it\n",
    "#import json\n",
    "#s = json.load( open(os.getenv ('PUI2016')+\"/fbb_matplotlibrc.json\") )\n",
    "#pl.rcParams.update(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Read in data\n",
    "I am reading in data from January 2015 with the function that I created getCitiBikeCSV. You are requested to use 2 months at least. It would be a good idea to use data from a colder and a warmer months, since there are more riders in the warm weather and ridership patterns may change with weather, temperature, etc. You should use data from multiple months, joining multiple datasets (thus addressing some systematic errors as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:48:09.386484",
     "start_time": "2017-10-05T16:48:06.821336"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#datestring = '201511'\n",
    "#getCitiBikeCSV(datestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-10-14 20:41:39--  https://s3.amazonaws.com/tripdata/201512-citibike-tripdata.zip\n",
      "Resolving s3.amazonaws.com... 52.216.224.235\n",
      "Connecting to s3.amazonaws.com|52.216.224.235|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 23145783 (22M) [application/zip]\n",
      "Saving to: “STDOUT”\n",
      "\n",
      "100%[======================================>] 23,145,783  45.8M/s   in 0.5s    \n",
      "\n",
      "2017-10-14 20:41:40 (45.8 MB/s) - written to stdout [23145783/23145783]\n",
      "\n",
      "--2017-10-14 20:41:40--  https://s3.amazonaws.com/tripdata/201511-citibike-tripdata.zip\n",
      "Resolving s3.amazonaws.com... 52.216.224.235\n",
      "Connecting to s3.amazonaws.com|52.216.224.235|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 34354395 (33M) [application/zip]\n",
      "Saving to: “STDOUT”\n",
      "\n",
      "100%[======================================>] 34,354,395  41.7M/s   in 0.8s    \n",
      "\n",
      "2017-10-14 20:41:41 (41.7 MB/s) - written to stdout [34354395/34354395]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O - 'https://s3.amazonaws.com/tripdata/201512-citibike-tripdata.zip' > 'dec_data.zip'\n",
    "!wget -O - 'https://s3.amazonaws.com/tripdata/201511-citibike-tripdata.zip' > 'nov_data.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_dec = zipfile.ZipFile('dec_data.zip', 'r')\n",
    "zip_dec.extractall()\n",
    "\n",
    "zip_nov = zipfile.ZipFile('nov_data.zip', 'r')\n",
    "zip_nov.extractall()\n",
    "\n",
    "dec_df = pd.read_csv('201512-citibike-tripdata.csv')\n",
    "\n",
    "dec = dec_df\n",
    "\n",
    "nov_df = pd.read_csv('201511-citibike-tripdata.csv')\n",
    "\n",
    "nov = nov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start station id</th>\n",
       "      <th>start station name</th>\n",
       "      <th>start station latitude</th>\n",
       "      <th>start station longitude</th>\n",
       "      <th>end station id</th>\n",
       "      <th>end station name</th>\n",
       "      <th>end station latitude</th>\n",
       "      <th>end station longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birth year</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1110</td>\n",
       "      <td>11/1/2015 00:00:00</td>\n",
       "      <td>11/1/2015 00:18:31</td>\n",
       "      <td>537</td>\n",
       "      <td>Lexington Ave &amp; E 24 St</td>\n",
       "      <td>40.740259</td>\n",
       "      <td>-73.984092</td>\n",
       "      <td>531</td>\n",
       "      <td>Forsyth St &amp; Broome St</td>\n",
       "      <td>40.718939</td>\n",
       "      <td>-73.992663</td>\n",
       "      <td>22545</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration           starttime            stoptime  start station id  \\\n",
       "0          1110  11/1/2015 00:00:00  11/1/2015 00:18:31               537   \n",
       "\n",
       "        start station name  start station latitude  start station longitude  \\\n",
       "0  Lexington Ave & E 24 St               40.740259               -73.984092   \n",
       "\n",
       "   end station id        end station name  end station latitude  \\\n",
       "0             531  Forsyth St & Broome St             40.718939   \n",
       "\n",
       "   end station longitude  bikeid    usertype  birth year  gender  \n",
       "0             -73.992663   22545  Subscriber      1981.0       2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nov.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(987245, 15) (804125, 15) (1791370, 15)\n"
     ]
    }
   ],
   "source": [
    "#combine the two months of data\n",
    "\n",
    "months = pd.concat([nov, dec])\n",
    "print nov.shape, dec.shape, months.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start station id</th>\n",
       "      <th>start station name</th>\n",
       "      <th>start station latitude</th>\n",
       "      <th>start station longitude</th>\n",
       "      <th>end station id</th>\n",
       "      <th>end station name</th>\n",
       "      <th>end station latitude</th>\n",
       "      <th>end station longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birth year</th>\n",
       "      <th>gender</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1110</td>\n",
       "      <td>11/1/2015 00:00:00</td>\n",
       "      <td>11/1/2015 00:18:31</td>\n",
       "      <td>537</td>\n",
       "      <td>Lexington Ave &amp; E 24 St</td>\n",
       "      <td>40.740259</td>\n",
       "      <td>-73.984092</td>\n",
       "      <td>531</td>\n",
       "      <td>Forsyth St &amp; Broome St</td>\n",
       "      <td>40.718939</td>\n",
       "      <td>-73.992663</td>\n",
       "      <td>22545</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-11-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1094</td>\n",
       "      <td>11/1/2015 00:00:01</td>\n",
       "      <td>11/1/2015 00:18:15</td>\n",
       "      <td>537</td>\n",
       "      <td>Lexington Ave &amp; E 24 St</td>\n",
       "      <td>40.740259</td>\n",
       "      <td>-73.984092</td>\n",
       "      <td>531</td>\n",
       "      <td>Forsyth St &amp; Broome St</td>\n",
       "      <td>40.718939</td>\n",
       "      <td>-73.992663</td>\n",
       "      <td>23959</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-11-01 00:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>520</td>\n",
       "      <td>11/1/2015 00:00:05</td>\n",
       "      <td>11/1/2015 00:08:45</td>\n",
       "      <td>536</td>\n",
       "      <td>1 Ave &amp; E 30 St</td>\n",
       "      <td>40.741444</td>\n",
       "      <td>-73.975361</td>\n",
       "      <td>498</td>\n",
       "      <td>Broadway &amp; W 32 St</td>\n",
       "      <td>40.748549</td>\n",
       "      <td>-73.988084</td>\n",
       "      <td>22251</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-11-01 00:00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>753</td>\n",
       "      <td>11/1/2015 00:00:15</td>\n",
       "      <td>11/1/2015 00:12:48</td>\n",
       "      <td>229</td>\n",
       "      <td>Great Jones St</td>\n",
       "      <td>40.727434</td>\n",
       "      <td>-73.993790</td>\n",
       "      <td>328</td>\n",
       "      <td>Watts St &amp; Greenwich St</td>\n",
       "      <td>40.724055</td>\n",
       "      <td>-74.009660</td>\n",
       "      <td>15869</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-11-01 00:00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>353</td>\n",
       "      <td>11/1/2015 00:00:22</td>\n",
       "      <td>11/1/2015 00:06:15</td>\n",
       "      <td>285</td>\n",
       "      <td>Broadway &amp; E 14 St</td>\n",
       "      <td>40.734546</td>\n",
       "      <td>-73.990741</td>\n",
       "      <td>151</td>\n",
       "      <td>Cleveland Pl &amp; Spring St</td>\n",
       "      <td>40.722104</td>\n",
       "      <td>-73.997249</td>\n",
       "      <td>21645</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-11-01 00:00:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration           starttime            stoptime  start station id  \\\n",
       "0          1110  11/1/2015 00:00:00  11/1/2015 00:18:31               537   \n",
       "1          1094  11/1/2015 00:00:01  11/1/2015 00:18:15               537   \n",
       "2           520  11/1/2015 00:00:05  11/1/2015 00:08:45               536   \n",
       "3           753  11/1/2015 00:00:15  11/1/2015 00:12:48               229   \n",
       "4           353  11/1/2015 00:00:22  11/1/2015 00:06:15               285   \n",
       "\n",
       "        start station name  start station latitude  start station longitude  \\\n",
       "0  Lexington Ave & E 24 St               40.740259               -73.984092   \n",
       "1  Lexington Ave & E 24 St               40.740259               -73.984092   \n",
       "2          1 Ave & E 30 St               40.741444               -73.975361   \n",
       "3           Great Jones St               40.727434               -73.993790   \n",
       "4       Broadway & E 14 St               40.734546               -73.990741   \n",
       "\n",
       "   end station id          end station name  end station latitude  \\\n",
       "0             531    Forsyth St & Broome St             40.718939   \n",
       "1             531    Forsyth St & Broome St             40.718939   \n",
       "2             498        Broadway & W 32 St             40.748549   \n",
       "3             328   Watts St & Greenwich St             40.724055   \n",
       "4             151  Cleveland Pl & Spring St             40.722104   \n",
       "\n",
       "   end station longitude  bikeid    usertype  birth year  gender  \\\n",
       "0             -73.992663   22545  Subscriber      1981.0       2   \n",
       "1             -73.992663   23959  Subscriber      1980.0       1   \n",
       "2             -73.988084   22251  Subscriber      1988.0       1   \n",
       "3             -74.009660   15869  Subscriber      1981.0       1   \n",
       "4             -73.997249   21645  Subscriber      1987.0       1   \n",
       "\n",
       "                 date  \n",
       "0 2015-11-01 00:00:00  \n",
       "1 2015-11-01 00:00:01  \n",
       "2 2015-11-01 00:00:05  \n",
       "3 2015-11-01 00:00:15  \n",
       "4 2015-11-01 00:00:22  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df is the dataframe where the content of the csv file is stored\n",
    "months['date'] = pd.to_datetime(months['starttime'])\n",
    "# note that with dataframes I can refer to variables as dictionary keys, \n",
    "# i.e. df['starttime'] or as attributes: df.starttime. \n",
    "months.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_months = months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1791370, 16)\n"
     ]
    }
   ],
   "source": [
    "months = original_months\n",
    "months.head(5)\n",
    "print(months.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1622892, 16)\n",
      "   tripduration           starttime            stoptime  start station id  \\\n",
      "0          1110  11/1/2015 00:00:00  11/1/2015 00:18:31               537   \n",
      "1          1094  11/1/2015 00:00:01  11/1/2015 00:18:15               537   \n",
      "2           520  11/1/2015 00:00:05  11/1/2015 00:08:45               536   \n",
      "3           753  11/1/2015 00:00:15  11/1/2015 00:12:48               229   \n",
      "4           353  11/1/2015 00:00:22  11/1/2015 00:06:15               285   \n",
      "\n",
      "        start station name  start station latitude  start station longitude  \\\n",
      "0  Lexington Ave & E 24 St               40.740259               -73.984092   \n",
      "1  Lexington Ave & E 24 St               40.740259               -73.984092   \n",
      "2          1 Ave & E 30 St               40.741444               -73.975361   \n",
      "3           Great Jones St               40.727434               -73.993790   \n",
      "4       Broadway & E 14 St               40.734546               -73.990741   \n",
      "\n",
      "   end station id          end station name  end station latitude  \\\n",
      "0             531    Forsyth St & Broome St             40.718939   \n",
      "1             531    Forsyth St & Broome St             40.718939   \n",
      "2             498        Broadway & W 32 St             40.748549   \n",
      "3             328   Watts St & Greenwich St             40.724055   \n",
      "4             151  Cleveland Pl & Spring St             40.722104   \n",
      "\n",
      "   end station longitude  bikeid    usertype  birth year  gender  \\\n",
      "0             -73.992663   22545  Subscriber      1981.0       2   \n",
      "1             -73.992663   23959  Subscriber      1980.0       1   \n",
      "2             -73.988084   22251  Subscriber      1988.0       1   \n",
      "3             -74.009660   15869  Subscriber      1981.0       1   \n",
      "4             -73.997249   21645  Subscriber      1987.0       1   \n",
      "\n",
      "                 date  \n",
      "0 2015-11-01 00:00:00  \n",
      "1 2015-11-01 00:00:01  \n",
      "2 2015-11-01 00:00:05  \n",
      "3 2015-11-01 00:00:15  \n",
      "4 2015-11-01 00:00:22  \n"
     ]
    }
   ],
   "source": [
    "# Remove all rows with NaN birthyear\n",
    "months = months.dropna(subset = ['birth year'])\n",
    "print(months.shape)\n",
    "print(months.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do(problem_number):\n",
    "    \"\"\" \n",
    "    problem_number is either 1 or 2, corresponding to:\n",
    "        1: Test whether trip durations of bikers is different during day vs night\n",
    "        2: Test whether age of bikers is different for Manhattan vs Brooklyn\n",
    "        \n",
    "    Each problem tests whether the distribution of feature_of_interest (duration or age) is \n",
    "    different for type_1 vs type_2 (day vs night, or Manhattan vs Brooklyn)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Doing problem %s...\" % problem_number)\n",
    "    \n",
    "    type_1_rows, type_2_rows = identify_types(problem_number) \n",
    "    feature_column = feature_of_interest(problem_number)\n",
    "    \n",
    "    sample_1 = feature_column[type_1_rows]\n",
    "    sample_2 = feature_column[type_2_rows]\n",
    "    \n",
    "    print(\"First few values of type 1\")\n",
    "    print(sample_1.head(5))\n",
    "    print(\"First few values of type 2\")\n",
    "    print(sample_2.head(5))\n",
    "    \n",
    "    alpha = 0.05\n",
    "    \n",
    "    # KS\n",
    "    ks_stat, p = scipy.stats.ks_2samp(sample_1, sample_2)\n",
    "    print(ks_null_hypothesis(problem_number))\n",
    "    print(\"p_value for KS: %s\" % p)\n",
    "    print(compare_p_to_alpha(p, alpha))\n",
    "    \n",
    "    # Let's make smaller samples for a reduced KS. Probably we will see a higher p-value.\n",
    "    random.seed(1)\n",
    "    sample_1_copy, sample_2_copy = [d for d in sample_1], [d for d in sample_2]\n",
    "    random.shuffle(sample_1_copy)\n",
    "    random.shuffle(sample_2_copy)\n",
    "    smaller_sample_1 = sample_1_copy[::20]\n",
    "    smaller_sample_2 = sample_2_copy[::20]\n",
    "    print(\"KS on smaller samples (1/20th the size):\")\n",
    "    ks_stat, p = scipy.stats.ks_2samp(smaller_sample_1, smaller_sample_2)\n",
    "    print(ks_null_hypothesis(problem_number))\n",
    "    print(\"p_value for KS: %s\" % p)\n",
    "    print(compare_p_to_alpha(p, alpha))\n",
    "    \n",
    "    \n",
    "    # We will need equal-length samples, so let's resample...\n",
    "    new_size = min(len(sample_1), len(sample_2))\n",
    "    print(\"For Pearson, reducing both samples to new_size: %s\" % new_size)\n",
    "    new_sample_1 = sample_1_copy[:new_size]\n",
    "    new_sample_2 = sample_2_copy[:new_size]\n",
    "    \n",
    "    # Pearson\n",
    "    rho, p = scipy.stats.pearsonr(new_sample_1, new_sample_2)\n",
    "    print(pearsonnr_null_hypothesis(problem_number))\n",
    "    print(\"p_value for Pearson: %s\" % p)\n",
    "    print(compare_p_to_alpha(p, alpha))\n",
    "    \n",
    "    # Spearmanr\n",
    "    rho, p = scipy.stats.spearmanr(new_sample_1, new_sample_2)\n",
    "    print(spearmannr_null_hypothesis(problem_number))\n",
    "    print(\"p_value for Spearman: %s\" % p)\n",
    "    print(compare_p_to_alpha(p, alpha))\n",
    "\n",
    "    \n",
    "def compare_p_to_alpha(p, alpha):\n",
    "    if p < alpha:\n",
    "        return \"p < alpha, so we reject the null hypothesis.\"\n",
    "    else:\n",
    "        return \"p >= alpha, so we do not reject the null hypothesis.\"\n",
    "    \n",
    "def feature_of_interest(problem_number):\n",
    "    \"\"\" Returns a column of values, with the same number of rows as the months dataframe. \"\"\"\n",
    "    if problem_number == 1:\n",
    "        return months['tripduration']\n",
    "    if problem_number == 2:\n",
    "        return 2015 - months['birth year']\n",
    "    \n",
    "def identify_types(problem_number):\n",
    "    \"\"\"\n",
    "    Returns (type_1_rows, type_2_rows), each of which is a column of True/False where Trues \n",
    "    correspond to rows in months of that type.\n",
    "    \"\"\"\n",
    "    \n",
    "    if problem_number == 1:\n",
    "        # Types are day and night\n",
    "        is_day = lambda d: 5 <= d.hour <= 19\n",
    "        is_night = lambda d: not is_day(d)\n",
    "        \n",
    "        type_1_rows = months['date'].apply(is_day)\n",
    "        type_2_rows = months['date'].apply(is_night)\n",
    "    elif problem_number == 2:\n",
    "        # Types are Manhattan and Brooklyn\n",
    "        # We'll choose coordinates of two points, and declare everything above the corresponding line \n",
    "        # to be Manhattan, and everything below is Brooklyn.\n",
    "        \n",
    "        bottom_left = (40.697409, -74.011974)\n",
    "        top_right = (40.721091, -73.969574)\n",
    "        \n",
    "        # Imagine vectors a, (bottom_left -> top_right), and b, (top_right -> new_point)\n",
    "        # If the cross product a x b is positive, the new point is in Manhattan\n",
    "        a = (top_right[0] - bottom_left[0], \n",
    "             top_right[1] - bottom_left[1])\n",
    "        b = (months['start station latitude'] - top_right[0],\n",
    "             months['start station longitude'] - top_right[1])\n",
    "        \n",
    "        cross_product = a[0] * b[1] - a[1] * b[0]\n",
    "        type_1_rows = cross_product > 0\n",
    "        type_2_rows = cross_product < 0\n",
    "    \n",
    "    return (type_1_rows, type_2_rows)\n",
    "\n",
    "\n",
    "##### Null hypotheses ##########################################################################\n",
    "def ks_null_hypothesis(problem_number):\n",
    "    prefix = \"The null hypothesis for KS is that the distribution of \"\n",
    "    if problem_number == 1:\n",
    "        suffix = \"trip duration is the same during the day vs during the night.\"\n",
    "    if problem_number == 2:\n",
    "        suffix = \"age is the same for trips originating in Manhattan vs Brooklyn.\"\n",
    "        \n",
    "    return prefix + suffix\n",
    "\n",
    "def pearsonnr_null_hypothesis(problem_number):\n",
    "    prefix = \"The null hypothesis for Pearson is that there is 0 correlation between\"\n",
    "    if problem_number == 1:\n",
    "        suffix = \"trip duration and an indicator variable for day vs night.\" \n",
    "    if problem_number == 2:\n",
    "        suffix = \"age and an indicator variable for originating in Manhattan vs Brooklyn.\"\n",
    "        \n",
    "    return prefix + suffix\n",
    "\n",
    "def spearmannr_null_hypothesis(problem_number):\n",
    "    prefix = \"The null hypothesis for Spearman is that there is no association between \"\n",
    "    if problem_number == 1:\n",
    "        suffix = \"trip duration and an indicator variable for day vs night.\"\n",
    "    if problem_number == 2:\n",
    "        suffix = \"age and an indicator variable for originating in Manhattan vs Brooklyn.\"\n",
    "    \n",
    "    return prefix + suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing problem 1...\n",
      "First few values of type 1\n",
      "1911    9668\n",
      "1912     790\n",
      "1913     555\n",
      "1914    1805\n",
      "1915     466\n",
      "Name: tripduration, dtype: int64\n",
      "First few values of type 2\n",
      "0    1110\n",
      "1    1094\n",
      "2     520\n",
      "3     753\n",
      "4     353\n",
      "Name: tripduration, dtype: int64\n",
      "The null hypothesis for KS is that the distribution of trip duration is the same during the day vs during the night.\n",
      "p_value for KS: 2.36667977115e-282\n",
      "p < alpha, so we reject the null hypothesis.\n",
      "KS on smaller samples (1/20th the size):\n",
      "The null hypothesis for KS is that the distribution of trip duration is the same during the day vs during the night.\n",
      "p_value for KS: 6.52071464349e-24\n",
      "p < alpha, so we reject the null hypothesis.\n",
      "For Pearson, reducing both samples to new_size: 207412\n",
      "The null hypothesis for Pearson is that there is 0 correlation betweentrip duration and an indicator variable for day vs night.\n",
      "p_value for Pearson: 0.818000030283\n",
      "p >= alpha, so we do not reject the null hypothesis.\n",
      "The null hypothesis for Spearman is that there is no association between trip duration and an indicator variable for day vs night.\n",
      "p_value for Spearman: 0.241663472632\n",
      "p >= alpha, so we do not reject the null hypothesis.\n"
     ]
    }
   ],
   "source": [
    "do(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing problem 2...\n",
      "First few values of type 1\n",
      "7     37.0\n",
      "21    23.0\n",
      "23    24.0\n",
      "38    31.0\n",
      "49    23.0\n",
      "Name: birth year, dtype: float64\n",
      "First few values of type 2\n",
      "0    34.0\n",
      "1    35.0\n",
      "2    27.0\n",
      "3    34.0\n",
      "4    28.0\n",
      "Name: birth year, dtype: float64\n",
      "The null hypothesis for KS is that the distribution of age is the same for trips originating in Manhattan vs Brooklyn.\n",
      "p_value for KS: 0.0\n",
      "p < alpha, so we reject the null hypothesis.\n",
      "KS on smaller samples (1/20th the size):\n",
      "The null hypothesis for KS is that the distribution of age is the same for trips originating in Manhattan vs Brooklyn.\n",
      "p_value for KS: 1.04440039013e-110\n",
      "p < alpha, so we reject the null hypothesis.\n",
      "For Pearson, reducing both samples to new_size: 150348\n",
      "The null hypothesis for Pearson is that there is 0 correlation betweenage and an indicator variable for originating in Manhattan vs Brooklyn.\n",
      "p_value for Pearson: 0.301663339752\n",
      "p >= alpha, so we do not reject the null hypothesis.\n",
      "The null hypothesis for Spearman is that there is no association between age and an indicator variable for originating in Manhattan vs Brooklyn.\n",
      "p_value for Spearman: 0.49247611982\n",
      "p >= alpha, so we do not reject the null hypothesis.\n"
     ]
    }
   ],
   "source": [
    "do(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the output required for this problem, for each question 1 and 2, including null hypothesis, p-value, and interpretation, is above.\n",
    "\n",
    "However, I want to include a description of the output of the scipy functions.\n",
    "\n",
    "stats.pearsonr takes two arrays and returns two values: pearson's correlation coefficient (in the range of -1 to +1, where 1 = perfectly positively correlated, 0 = not correlated, and -1 = perfectly negatively correlated), and also a two-tailed p-value.\n",
    "\n",
    "stats.spearmanr returns a rho, also known as the spearman correlation rank order coefficient (in the range of -1 to +1, where 1 = perfectly positively correlated, 0 = not correlated, and -1 = perfectly negatively correlated), and also a two-sided p-value. It does not assume that the data are normally distributed. \n",
    "\n",
    "stats.ks_2samp returns the KS statistic and also a p-value as floats. A small KS statistic or a large p-value prevents us from rejecting the null hypothesis."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "PUI2016_Python2",
   "language": "python",
   "name": "pui2016_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "135px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
